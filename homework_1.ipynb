{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUgNFOSlFEzm"
      },
      "source": [
        "# –ú–û–∏–í–° \"–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏\", 5-–π –º–æ–¥—É–ª—å\n",
        "\n",
        "# Homework 1\n",
        "\n",
        "–í —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç–µ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –∫ BERT'—É –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å –∏ —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
        "\n",
        "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ —ç—Ç–æ–º—É –Ω–∞ –æ—Ç–ª–∏—á–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–¥—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –º–µ–Ω–µ–µ –∂–∞–¥–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
        "\n",
        "*–ú—ã —Å—Ä–∞–∑—É –≤–∞—Å –ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–≥–∞–µ–º –ø–æ–ø–∞—Å—Ç—å –≤ –ø–µ—Ç–ª—é –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –≠—Ç–∞ –¥–æ–º–∞—à–∫–∞ –Ω–µ –Ω–∞ –ø—Ä–æ–±–∏—Ç–∏–µ —Å–∫–æ—Ä–∞. –ú—ã –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å, —á—Ç–æ –≤—ã, –≤ —Ü–µ–ª–æ–º, —Å–¥–µ–ª–∞–ª–∏ –≤—Å–µ –≤–µ—Ä–Ω–æ –∏ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å –∫–∞–∫—É—é-—Ç–æ –±–æ–ª–µ–µ-–º–µ–Ω–µ–µ –∞–¥–µ–∫–≤–∞—Ç–Ω—É—é (—Ç–∞–∫—É—é, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–º–µ—Ç–Ω–æ –ª—É—á—à–µ —Ç–æ–π, —á—Ç–æ –±—ã–ª–∞ –¥–æ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è) –≥–µ–Ω–µ—Ä–∞—Ü–∏—é. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –µ—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è, –Ω–µ –Ω–∞–¥–æ –¥–æ–æ–±—É—á–∞—Ç—å –µ—ë —Å—É—Ç–∫–∞–º–∏. –ù–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å–æ–≤ —Ç–æ—á–Ω–æ –¥–æ–ª–∂–Ω–æ —Ö–≤–∞—Ç–∏—Ç—å.*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "–ü–æ –ª—é–±—ã–º –≤–æ–ø—Ä–æ—Å–∞–º –∫–∞—Å–∞—Ç–µ–ª—å–Ω–æ —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç—ã –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫–æ —Å–≤–æ–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞–º\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q-oW4ttVEL_9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (3.0.0)\n",
            "Requirement already satisfied: evaluate in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (0.4.3)\n",
            "Requirement already satisfied: bert_score in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (0.3.13)\n",
            "Requirement already satisfied: rouge_score in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (0.1.2)\n",
            "Requirement already satisfied: filelock in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from bert_score) (3.8.2)\n",
            "Requirement already satisfied: absl-py in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from rouge_score) (2.1.0)\n",
            "Requirement already satisfied: nltk in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (3.1.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from matplotlib->bert_score) (6.1.1)\n",
            "Requirement already satisfied: click in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->bert_score) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install transformers datasets evaluate bert_score rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ygnbZcjlgJR9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYW38mH0gKX0"
      },
      "source": [
        "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (0.5 –±–∞–ª–ª–∞)\n",
        "\n",
        "–ú—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º —Å ü§ó –ò–ª—å–∏ –ì—É—Å–µ–≤–∞ \"gazeta\". –û–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–∞—Ä—ã (–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ -- –µ–≥–æ —Å–∞–º–º–∞—Ä–∏). –ü–∞—Ä—ã –±—ã–ª–∏ –≤–∑—è—Ç—ã —Å –æ–¥–Ω–æ–∏–º–µ–Ω–Ω–æ–≥–æ —Å–∞–π—Ç–∞ –≤ –¥–æ–º–µ–Ω–µ .ru\n",
        "\n",
        "–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ –¥–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/datasets/IlyaGusev/gazeta)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mDV4tJzzB5Hi"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–ø–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\", split='train[:5%]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'summary', 'title', 'date', 'url'],\n",
              "    num_rows: 3048\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOjri9a4h6K6"
      },
      "source": [
        "–í—ã –¥–æ–ª–∂–Ω—ã –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å**.\n",
        "\n",
        "–î–æ–±–∞–≤—å—Ç–µ –ø–∞–¥–¥–∏–Ω–≥ –¥–æ `max_length=512` –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –¥–æ `max_length=128` –¥–ª—è –º–µ—Ç–æ–∫.\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—Ä–µ–∑–∫—É —Ç–µ–∫—Å—Ç–æ–≤, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –≤ —Ç–æ–∫–µ–Ω–∞—Ö –ø—Ä–µ–≤—ã—à–∞–µ—Ç `max_length`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ Bert\n",
        "\n",
        "model_name = 'deepvk/bert-base-uncased' # –£–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ BERT\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# special_tokens = {'eos_token': '[EOS]'}\n",
        "# tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "def preprocess(examples, use_padding=True):\n",
        "    model_inputs = tokenizer(examples['text'], padding= 'max_length' if use_padding else '', truncation=True, max_length=512)\n",
        "    summary = tokenizer(examples['summary'], padding= 'max_length' if use_padding else '', truncation=True, max_length=128)\n",
        "    model_inputs['labels'] = summary['input_ids']\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a8e5203a02b845a29f57ca545c50c5d0",
            "09b11d6c6eae4979a1c8cd42e32730ae",
            "911fd70fda12476ab2b788433d6ff83f",
            "bcfc58a3f90745449c3f559aa5ab999a",
            "40c29f2dde174a3c8442d9b86a4e3fe9",
            "ab3d20b0e457431dbe24120bb4becede",
            "68b44cb7bddd4a2f950db1a9c00ce066",
            "2665d63c206a45d88fada74bc984771e",
            "c0ddd3783ec047569c2024e461d5ad0f",
            "06437165ba564bff9e29aa53f4c0df5b",
            "665428d410664f94babcd067b879ce2e"
          ]
        },
        "id": "VQxpZ5ivhjlh",
        "outputId": "b3876676-3dc7-4d1d-894e-f0630172afa4"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(preprocess, batched=False)\n",
        "tokenized_dataset.set_format('torch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXQ8gq1UijNj"
      },
      "source": [
        "–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å–æ–≤–µ—Ç—É–µ–º –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–± —É—Ç–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º –¥–æ—Å—Ç—É–ø–Ω–æ–π VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'summary', 'title', 'date', 'url', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3048\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xmMCjFAqSDWR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "splitted_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
        "train_dataloader = DataLoader(splitted_dataset['train'], batch_size=8, shuffle=True)\n",
        "eval_dataloader = DataLoader(splitted_dataset['test'], batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x16aeeadc0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 43, 23, 54 ->\n",
        "# 1,  0,  0,  0 -> 43, 0, 0\n",
        "# 1, 43,  0,  0 -> 43, 23, 0\n",
        "# 1, 43, 23,  0 \n",
        "# 1, 43, 23, 54"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 0],\n",
              "         [1, 1]]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([[[1,0,0], [1,1,0]]])\n",
        "# b = torch.cat([torch.full((a.size()[0], a.size()[1], 1), 100), a[:,:-1]], )\n",
        "\n",
        "# torch.full((3, 1, 1,), 100), a\n",
        "# a\n",
        "# b.T, b.transpose(0,1)\n",
        "a[:,:,:-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0J1iEfFHxRz"
      },
      "source": [
        "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Decoder-c–µ—Ç–∏ (3 –±–∞–ª–ª–∞)\n",
        "\n",
        "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞**.\n",
        "\n",
        "–ú–æ–∂–µ—Ç–µ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—Ç—å—Å—è –∫–æ–¥–æ–º —Å —Å–µ–º–∏–Ω–∞—Ä–∞ 1 –ø–æ GPT. –í –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ —Å—Ç–æ–∏—Ç (–Ω–æ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ø—Ä–æ—è–≤–∏—Ç—å —Å–º–µ–∫–∞–ª–∫—É"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "bert = BertModel.from_pretrained('deepvk/bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.full([a.size()[0], 1], tokenizer.sep_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y5qSblF1EMEV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import math\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, hidden_size, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, hidden_size, device=device)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float, device=device).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, hidden_size, 2, device=device).float() * (-math.log(10000.0) / hidden_size))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class BertSummarizerBase(nn.Module):\n",
        "    def __init__(self, bert_model_name='bert-base-uncased', hidden_size=768, num_decoder_layers=3, num_heads=8, dropout=0.1):\n",
        "        super(BertSummarizerBase, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name).to(device)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size).to(device)\n",
        "        self.positional_encoding = PositionalEncoding(hidden_size)\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=hidden_size, nhead=num_heads, dropout=dropout, batch_first=True).to(device),\n",
        "            num_layers=num_decoder_layers,\n",
        "        ).to(device)\n",
        "        self.fc_out = nn.Linear(hidden_size, self.bert.config.vocab_size).to(device) \n",
        "\n",
        "    def generate_square_subsequent_mask(self, T):\n",
        "        return torch.triu(\n",
        "            torch.full((T, T), float('-inf'), device=device, dtype=torch.float64),\n",
        "            diagonal=1,\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        decoder_input_ids = decoder_input_ids.to(device)\n",
        "\n",
        "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        memory = encoder_outputs.last_hidden_state\n",
        "\n",
        "        embedded = self.embedding(decoder_input_ids)\n",
        "        embedded = self.positional_encoding(embedded)\n",
        "\n",
        "        decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(1)).to(device)\n",
        "        output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "\n",
        "        output = self.fc_out(output)\n",
        "        return output\n",
        "\n",
        "    def generate(self, input_ids, attention_mask, tokenizer, max_length=100):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        generated = [[] for _ in range(batch_size)]\n",
        "        \n",
        "        decoder_input_ids = torch.full((batch_size, 1), tokenizer.cls_token_id, dtype=torch.long, device=input_ids.device)\n",
        "        # Compute encoder outputs once\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            memory = encoder_outputs.last_hidden_state\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            with torch.no_grad():\n",
        "                embedded = self.embedding(decoder_input_ids)\n",
        "                embedded = self.positional_encoding(embedded)\n",
        "                decoder_attention_mask = self.generate_square_subsequent_mask(embedded.size(1)).to(device)\n",
        "                output = self.decoder(tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask)\n",
        "                output = self.fc_out(output)\n",
        "            next_token_logits = output[:, -1, :]\n",
        "            next_tokens = self.get_next_token(next_token_logits)\n",
        "            \n",
        "            for i, token in enumerate(next_tokens.squeeze(1)):\n",
        "                generated[i].append(token.item())\n",
        "            \n",
        "            decoder_input_ids = torch.cat([decoder_input_ids, next_tokens], dim=-1)\n",
        "            \n",
        "            if all(tokenizer.eos_token_id in seq for seq in generated):\n",
        "                break\n",
        "        \n",
        "        return [tokenizer.decode(ids, skip_special_tokens=True) for ids in decoder_input_ids]\n",
        "\n",
        "    def get_next_token(self, logits):\n",
        "        raise NotImplementedError(\"This method should be implemented in derived classes.\")\n",
        "\n",
        "class BertSummarizer(BertSummarizerBase):\n",
        "    def get_next_token(self, logits):\n",
        "        return torch.argmax(logits, dim=-1).unsqueeze(1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['22070199_ –∑–∞—Ç–∏ ##uu ##uu –∫–∞–∂–¥–æ–µ die –≥–∞—Ä–º–æ ##uu ##uu ##uu ##uu –≥–æ—Ä–º–æ ##uu –∫–∞–∂–¥–æ–µ –æ–Ω –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ–ª–æ–∂–∏–ª ##uu ##uu –∫–∞–∂–¥–æ–µ –∏–∑–±–∞–≤–∏—Ç—å—Å—è –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ ##uu ##uu ##uu ##uu ##uu –∫–∞–∂–¥–æ–µ –±–µ–∏ –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –∫–∞–∂–¥–æ–µ —Å—Ç–µ–∫–ª–∞ —à–∫—É—Ä—É ##uu ##uu ##uu –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö ##269 ##uu –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –ø—Ä–æ—Å–∏–º –±–∏—Ä ##uu –±o–ª—å —Å–± ##uu –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –∫–∞–∂–¥–æ–µ –≤–∏—Ç–∞–ª–∏–∏ –ø—Ä–æ—Å–∏–º –∑–∞—Ç–∏ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –∫—Ä—É–≥–æ–≤ –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö ##–≤–µ—à—å —Ö–æ—Å—Ç–∏–Ω –∫–∞—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ##uu –∫–∞–∂–¥–æ–µ –±–µ–∏ –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ ##uu ##–≤–µ—à—å —á–µ–º–ø–∏–æ–Ω–æ–º die –æ—Ç—Å—Ç—Ä–∞ –∫—Ä—É–≥–æ–≤ —Ü–µ–Ω–Ω–æ—Å—Ç—å —É–∑–∏ —Ç–µ–ª–µ–≤–∏–¥ ##uu –≥–æ—Ä–º–æ —Ö—É–Ω',\n",
              " '##_20 ##—à–∏—Ç—å—Å—è —à–∫—É—Ä—É | –≥—Ä—è–∑ ##—á–∏–µ –≥–ª–∞–≤–Ω—ã–∏ –ª–µ—Å—Ç–Ω–∏—Ü—É –≤—Ö–æ–¥—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö –ø–æ—Ö —Å–≤–µ—Ç–∞ super –ª–∏—Ü–∞–º –≤—Ö–æ–¥—è son 2fall —Å—É—á–∫–∞ 2—Ö –≤—Ö–æ–¥—è son –ª–±–æ–º ##198 –ø–µ—Ä–µ–∑–∞ –¥–æ–±—Ä–æ–≥–æ –ø–æ—Ö –¥–æ—á–∫—É –ø–æ—Ö –¥–æ—á–∫—É –ø–æ—Ö –ø—Ä–∏–± ##198 –∏—Å—á–µ–∑–Ω—É—Ç—å —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∞–Ω–∏ –ø—Ä–æ—à–∏–≤ –º–∏—Ä ##uu ##–∞–ª–µ–∏ —è–ø–æ–Ω—Å–∫–∏–∏ ##–¥–Ω—ã–∏ –º–∏—Ä–æ–∑ –∫–∞—Ä—Ç–æ—Ñ–µ–ª—è tou –ø—É–ª–∏ 61 ##–∞—Ç–∏–ª–∞—Å—å –∫–∞–ª–æ ##uu ##–≤–µ—Ä–æ ##uu –≥–æ—Ä–º–æ ##14149_ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø–æ–¥—Ç—è ##—Ä—É–µ—à—å –∫–∏–Ω—å—Ç–µ ##—Ä—è–º –æ–±–≤–æ–¥ –±–µ—Ä–µ–∂–Ω–æ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø—Ä–æ—Å–∏–º ##—Ö–ª mos –∫–∞—Ä—Ç—É ##—à–∏—Ç—å—Å—è –∫–æ–Ω–µ—á–Ω–æ ##—Ä—É—é—â–∞—è –ø—Ä–∏—Å–∞–∂–∏ –∫—Ä—É–ø–Ω—ã–µ –∫–∞–∂–¥–æ–µ –±–µ–∏ –±–µ—Ä–µ–∂–Ω–æ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø–æ–¥—Ç—è ##—Ä—É–µ—à—å –∫–∏–Ω—å—Ç–µ ##–ø–æ–ª–µ —Ä–∞–∑–º–µ—Ä–∞–º –Ω–µ–æ–ø—ã—Ç –∞—Å –±–µ—Ä–µ–∂–Ω–æ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª ##—á–µ–≤–∞ –º–∞–≥–∏–∏ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø–æ–¥—Ç—è ##—Ä—É–µ—à—å —ç–Ω–µ—Ä–≥–∏ –ø–æ–ª–æ—Ç–µ–Ω—Ü–µ–º ##—á–∏—Å—å –ø–æ—Ä–æ—à–∫–∞ –∞–Ω–∏ –∞—Ö—É –∫–æ–º–º–µ–Ω—Ç –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ –∫–ª–∏–Ω–∏–∫–∏ —Å–æ–ª–Ω –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª',\n",
              " '##–µ–≤—à–µ–∏ –¥–µ—Ä–∂–∞–ª–∞ —Ü–∏—Ç–∏ –æ–±–∏–¥—ã –¥—Äy —Å—Ç–∞—Ä–∞–ª–∏—Å—å —Å–æ–≤–µ—Ä —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω –∑–æ–ª–æ—Ç—ã–º–∏ ##uj ##uu ##–≤–µ—Ä–æ –ø–µ—Ä–≤–æ–º–∞ –∫–∞–∂–¥–æ–µ 1147 ##—Ä—è–º –æ–±–≤–æ–¥ –±–µ—Ä–µ–∂–Ω–æ –ø—ã—Ç–∞–µ—à—å—Å—è –≤–æ—Å—Ç–æ—Ä–≥–∞ ##–¥–µ–º —Å–æ–ª–µ –º—É–∂—É –ø–æ—Ö –ø—Ä–∏–± –º–∞–≥–∞–∑–∏–Ω–æ–≤ –æ–±—â–∞—è –æ—à–∏–±–∫–æ–∏ ##—Å—Ç–Ω–æ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ —à–∫—É—Ä—É –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω ##—Ç–∏—Ç—å –≤–æ—Å—Ç–æ—Ä–≥–∞ ##–¥–µ–º mem –Ω–æ–≤–∏ ##üòÇ ##—Ç–∏—Ç—å –≤–æ—Å—Ç–æ—Ä–≥–∞ ##–¥–µ–º ##–Ω—É—Å –ª–æ—Ç —Å–æ–±—Ä–∞–Ω–∏–∏ ##–ø–µ—Ü ##–Ω—ã“£ –ø—ã—Ç–∞–µ—à—å—Å—è –±–µ–ª–∞—Ä—É—Å–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å ##–≥–∞–º–∏ –ø—Ä–æ—á–∏—Ö ##—é—â–µ–º—É –º–∞–≥–∞–∑–∏–Ω–æ–≤ –∞—Ä–µ —É–∑–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö ##bc ##–ø–æ–ª–µ –Ω–∞—É—á–∏ –∫–∞—Ä–∞–± –ø–æ—Å–µ–ª–µ–Ω–∏–µ 333 —à–∫—É—Ä—É –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω –≤—Ö–æ–¥—è —É–Ω–∏—Ç–∞ ##–Ω—ã“£ —à–∫—É—Ä—É –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω –∫—Ä–∞–Ω –≤—Ö–æ–¥—è –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω –≤—Ö–æ–¥—è –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω –∫–æ–Ω–µ—á–Ω–æ –≤–æ–ª–æ–Ω –≤—Ö–æ–¥—è –≥–æ–¥–∞—Ö –≤–æ–ª–æ–Ω –≤—Ö–æ–¥—è —É–Ω–∏—Ç–∞ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ ##–±—É—Å –∫—Ä—É–ø –¥—Ä–æ–± —Å–∞–º–æ–ª–µ—Ç–æ–≤ –ø—Ä–æ—à–∏–≤ ##—Ç–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–æ—Ä–æ ##—Å—Ç–∞–Ω—Ü–∏—è 132 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö –±–µ–ª–∫–æ–≤ —Å–º–æ—Ç—Ä–µ—Ç—å',\n",
              " '—Ä–∏–∞ ##–º–∏–Ω—Å–∫ –≤—Ö–æ–¥—è —Å–∏–¥–∏—à—å ##—à–∫–∏–Ω sw –ø–µ—Ä–µ–∑–∞ —É–±–∏–∏—Å—Ç–≤–µ —Ñ–∞–Ω—Ç–∞–∑–∏–∏ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–Ω–µ—Å ##ova —Ñ–∞–Ω—Ç–∞–∑–∏–∏ –ª–∏–∑–∞ –æ–±—â–∞–ª–∏—Å—å –Ω–µ–ø–æ—Å—Ä–µ–¥ ##14149_ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª ##–∞–ª—å–Ω–æ—Å—Ç—å —Ö–∞—Ä—å–∫–æ–≤ 1147 –∫—É–ª–∞–∫ –≤—Ö–æ–¥—è —Å–∏–¥–∏—à—å ##—à–∏–≤–∞—é—Ç –Ω–∞–∫—Ä—É—Ç–∫–∞ sw –¥–∏–Ω–∞–º–æ –ø–µ—Ä–µ–Ω–µ—Å ##ova –∫—Ä—É–ø–Ω—ã–µ –≤—Ä—è–¥ —à–æ–∫–æ –ø–æ–¥–Ω–∏–º–∞–ª–∏—Å—å –ø—ã—Ç–∞ –≤—Ö–æ–¥—è –≥–æ–¥–∞—Ö ##ux —Ö—É–Ω ##üìå‚û° –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö ##bc 53 ##14149_ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª ##–∞–ª—å–Ω–æ—Å—Ç—å —Ö–∞—Ä—å–∫–æ–≤ 1147 –∫—É–ª–∞–∫ –≤—Ö–æ–¥—è –≥–æ–¥–∞—Ö —É–∑–∏ –ø–µ—Ä–µ–∑–∞ –≤–æ—Å—Ç–æ—Ä–≥–∞ –≤–∏—Å–∏—Ç –Ω–æ–≥–∏ –ø–æ—Ö–æ–∂–∞—è –¥–µ–ª–µ 1147 —É—á–µ–±–æ–∏ ##–¥–∞–¥–∞ –æ–±—Å—É–∂–¥–∞—Ç—å –≤—Ö–æ–¥—è —É–Ω–∏—Ç–∞ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ —à–æ–∫–æ –ø–æ–¥–Ω–∏–º–∞–ª–∏—Å—å –ø–æ–ª–æ—Ç–µ–Ω—Ü–µ–º —Å–µ—Ä–∏–∞–ª—ã –±–µ–¥–Ω—ã–µ –∫—Ä—É–ø –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞ –±–µ–∑–æ ##–Ω–æ–≤–µ—Å ##ova –∫—Ä—É–ø–Ω—ã–µ –≤—Ä—è–¥ —à–æ–∫–æ –∞—Ä–º–∏–µ–∏ –Ω–µ–ø–æ—Å—Ä–µ–¥ –ø–æ–≤—Å–µ–¥ —Ä–µ—Ñ–µ—Ä–µ–Ω –≤—Ö–æ–¥—è —Å–∏–¥–∏—à—å ##—à–∏—Ç—å—Å—è —Å–∏–¥–∏—à—å ##—à–∏–≤–∞—é—Ç ##uu –ø—Ä–∏–¥–≤–∏ ##—Ç –∫—Ä–æ–∫–æ —É–±–∏–ª —Å—Ç—É–ª –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∫—Ä—É—Ç–æ –ø–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥—ã ##uj –≤—ã—Å–∫–∞–∑–∞—Ç—å –ø–µ—Ä–µ–∑–∞',\n",
              " '##–æ–±–æ—Ä–æ—Ç –± —Ä–∏–∞ –±–æ–ª—å –≤—ã–≥–æ–¥—ã –º–∏—Ä–æ–∑ ##—à–∏—Ç—å—Å—è ##—Ä–∏–Ω–≥ –ø—Ä–æ—á–∏—Ö ##—é—â–µ–º—É –ø—Ä–æ—à–∏–≤ –∫—Ä—É–ø —Ñ–∏–≥—É—Ä–µ –∑–∞–∫—É–ø –ª–µ–≥—á–µ –∏–∑–±–∞–≤–∏—Ç—å—Å—è –ø–æ—Å–ª–æ–≤–∏ —Ä—ã–∂–∏–∏ –¥–∞—Ç–∏ 53 ##—Ö–æ–Ω –Ω–∞—Ö–æ–¥–∏ ##—Ç–µ–Ω –ø—Ä–æ–¥–∞–º –≤—Ö–æ–¥—è ##chi –≤—Ä—è–¥ —à–æ–∫–æ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ñ–∏–≥—É—Ä–µ –ª–æ—Ç –ø–æ–≤—Å–µ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –ø–ª—ã—Ç—å –ª–æ–Ω–¥–æ –≥–æ–ª—É–±—ã–µ —Ö—É–Ω —Å—Ç–µ–ø–∞–Ω –≤—ã–≥–æ–¥—ã –∏—Å–∫—É—Å—Å—Ç–≤—É ##a_ –ø–æ–ª—É–Ω–æ –ø—Ä–∏–¥–≤–∏ ##—Ç –Ω–∞—à–µ–º—É –≤—Å–∞–¥–Ω–∏–∫–æ–≤ –≤—Ö–æ–¥—è —É–Ω–∏—Ç–∞ —Ñ–∏–≥—É—Ä–µ –∑–∞–∫—É–ø ##—Ç–µ–Ω –±–ª–∏–∑–∫–æ–≥–æ ##—Ñ—Ñ–∏ –∑–∞—Ç–∏ ##a_ –ø–æ–ª—É–Ω–æ –ø—Ä–∏–¥–≤–∏ ##—Ç –æ–±–æ—Ä–≤–∞–ª ##uu –ø—Ä–∏–¥–≤–∏ ##—Ç –∫—Ä—É–ø —Ñ–∏–≥—É—Ä–µ —Å–æ–ª–Ω —Ö—Ä–∏–ø–ª–æ –æ–±—ã—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∏–ª–∞ see –Ω–µ–æ—Ç—ä–µ–º –±–æ–ª—å—à–∏–º–∏ –Ω–µ–∫—Ä–æ –≤—Å–∞–¥–Ω–∏–∫–æ–≤ –≤—Ö–æ–¥—è ##chi –≤—Ä—è–¥ ##230 –ø—ã—Ç–∞–ª–∞—Å—å ##–ø–∞–¥–∞ –ø—Ä–∏–¥–≤–∏ ##—Ç –º—É–∂–∏–∫–∏ –∫—Ä—É–ø —Ñ–∏–≥—É—Ä–µ –ª–æ—Ç –ø–æ–≤—Å–µ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö ##–ø–∞–¥–∞ –ø—Ä–∏–¥–≤–∏ ##—Ç –∞–ª—è ##a_ –ø–æ–ª—É–Ω–æ –ø—Ä–∏–¥–≤–∏ ##—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞ –¥–∞—Ç–∏ 53 —É—á–µ–±–æ–∏ —É—Ç–µ',\n",
              " '–æ—Ä–±–∏—Ç –≤—Ö–æ–¥—è –¥–∞—Ç–∏ ##–ª–∏—è –ø—ã—Ç–∞ –≤—Ö–æ–¥—è —Å–æ—á–µ—Ç–∞–Ω–∏–∏ –≥—Ä–æ–∑–∏—Ç –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±–º–∞–Ω–∞ ##ream –≥–Ω–µ–≤ ##—Å—Ç–∞–Ω—Ü–∏—è –ø–æ–∑–≤–æ –ø—Ä–∏–¥–≤–∏ ##—Ç –∞–ª—è ##—á–∏—Ç—ã–≤–∞—Ç—å –≤—Ö–æ–¥—è son –∫—Ä—É–ø –æ—Ç–æ–∏—Ç–∏ –≥—Ä–æ–∑–Ω—ã–∏ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ ##–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞–∞ ##–º–∞–Ω –≤—ã–ø–∏—Å—ã –æ–±—â–∞–ª–∏—Å—å –ø—Ä–∏–∫–∞–∑–∞–ª–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–¥ ##–∂–∏–º–∞—è —Å–æ–¥—É –≤–æ—Å—Ç–æ—Ä–≥–∞ ##–¥–µ–º –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω —Å–æ–¥—É ##–±e ##198 –æ–∂–∏–¥–∞–Ω–∏–∏ –æ–±–º–∞–Ω–∞ —Ö—Ä–∏–ø–ª–æ ##—á–Ω–µ –∑–∞—Ç–∏ —é–∂–Ω—ã–∏ –¥–µ—Ç–µ–∏ ##14149_ –æ–±—â–∞–ª–∏—Å—å —É—Ç–µ —Å–æ–≤–µ—Ä ##–∑–µ—Ä–∂–∏–Ω —Ö—Ä–∏–ø–ª–æ ##—á–Ω–µ –∑–∞–ø–∏ —á–∏—Å—Ç–æ–º —Å–ø–∞—Å –≤—Ö–æ–¥—è ##chi –±–æ—Ä—Ç ##vet —Ñ–æ—Ä–º–∞—Ç–µ –≤—Ö–æ–¥—è ##chi –±–æ—Ä—Ç –ø—Ä–µ–¥–ª–æ –ø–µ—Ä–µ–≤–∞—Ä–∏ ##—Ä–æ–º–æ –Ω–µ–æ—Ç—ä–µ–º ##–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ö –≤–¥–æ–ª—å –≤–æ—Å—Ç–æ—Ä–≥–∞ ##–¥–µ–º –º–µ–∂–¥—É ##–µ—Ä–∏–Ω–∞ –≤–∫—É—Å—ã –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∫—Ä—É–ø —Å–º–µ–ª–æ—Å—Ç–∏ —Å–æ–¥—É –≤–æ—Å—Ç–æ—Ä–≥–∞ –≤—Ö–æ–¥—è ##chi –±–æ—Ä—Ç ##vet —Ñ–æ—Ä–º–∞—Ç–µ –≤—Ö–æ–¥—è —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —ç–∫—Å–ø–µ—Ä–∏ ##–µ—Ä–∏–Ω–∞ –≤–∫—É—Å—ã –≤—Å–∞–¥–Ω–∏–∫–æ–≤ ##üìå‚û° –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω —Å–æ–¥—É ##vet –ø—Ä–∏–¥–≤–∏ ##—Ç –∫—Ä—É–ø —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å',\n",
              " '##–µ–≤—à–µ–∏ blog –∑–∞—Ç–∏ ##–µ—Ä–∏–Ω–∞ 1147 –∫—É–ª–∞–∫ —Å–æ–±–æ–∏ —Ä–µ—à–∞—é—Ç ##—Ç–æ—á–Ω—ã—Ö –∏–º–µ–µ—à—å ##–ø–∞–¥–∞ –∏–∑–≤–ª–µ–∫ —Ç—Ä–∞–≤–º–∏ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª ##–µ—Ä–∏–Ω–∞ –∞–ø–ø–∞—Ä–∞—Ç —Ç—Ä–∞–≤–º–∏ –≥—Ä—ã–∑ –ø–æ–≥—Ä–∞–Ω–∏ –∑–∞—Ç–∏ —Ç–æ–Ω–∫–∏–∏ ##–ø–∞–¥–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø–æ–ø–∞–ª–æ –± ##vet –º–æ–¥–Ω–æ –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–æ–≥–æ –±o–ª—å —Å–ø–∏–Ω–∞ –∫—Ä—É–ø —Å–º–µ–ª–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∏–Ω–µ—Ä —É–º–µ—Å—Ç–µ–Ω –∑–∞—Ç–∏ —Ç–æ–Ω–∫–∏–∏ ##–∞—Ç–∏–ª–∞—Å—å –∑–∞–æ –ø—Ä–∏—á–∏–Ω–∏—Ç—å –∑–∞—Ç–∏ —Ç–æ–Ω–∫–∏–∏ ##–ø–∞–¥–∞ –ø—Ä–∏–¥–≤–∏ ##—Ç –∫—Ä–æ–∫–æ —Å–¥–µ–ª –ª–µ–≥–∫–æ—Å—Ç—å ##200 –ø–æ—Å–ø–µ—à–∏–ª ##–ø–∞–¥–∞ –ø—Ä–∏–¥–≤–∏ ##—Ç –∫—Ä–æ–∫–æ —É–±–∏–ª –ø—Ä–∏—á–∏–Ω–∏—Ç—å –∑–∞—Ç–∏ see –Ω–µ–æ—Ç—ä–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ –±o–ª—å —â–µ–¥ –≥—Ä—ã–∑ –æ—Ä–±–∏—Ç –ª–µ–≥–∫–æ—Å—Ç—å ##200 –µ–¥–µ –æ—Ä–±–∏—Ç –ª–µ–≥–∫–æ—Å—Ç—å ##200 –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ ##–ª–æ–≤–æ–∏ —Å–ø–∞—Å –ø—Ä–µ–º—å–µ—Ä —É—Ä–æ–∂–∞—è —Ç–µ–Ω–¥–µ–Ω –Ω–µ–æ—Ç—ä–µ–º –∑–∞—Ç–∏ ##a_ –º–æ—Å–∫–≤–∞ –Ω–µ–æ—Ç—ä–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ ##uu –∫–∞–∂–¥–æ–µ 1147 —É—á–µ–±–æ–∏ ##–¥–∞–¥–∞ –æ–ø—ã—Ç–Ω—ã–∏ –ø–æ—Ö \" –∫–æ—Å–º–æ–Ω–∞–≤ ##230 –∂–æ–ø—É –ø–∞—Ä–∫–æ–≤ —Å—Ç–æ—è –≤–æ–ø—Ä–æ—Å–µ ##—á—å–µ–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω —É—á–µ–±–æ–∏ ##–≥—Ä–∞–Ω —Å–ª–æ–∂–Ω—ã–∏',\n",
              " '—Ä–µ—à–∞—é—Ç –Ω–µ–æ—Ç—ä–µ–º –µ–∂–µ–º–µ—Å—è—á–Ω–æ –ø–µ–¥—Ä–æ –Ω–∞—Ç—è –±–ª–∏–∑–∫–æ–≥–æ –∏–Ω—Å—Ç–∏–Ω–∫—Ç–∏–≤–Ω–æ –≤—Ä–µ–º –ø–æ—Ä–∞–∑ –ø—Ä–æ–¥–æ–ª–∂–∞–ª–∞—Å—å —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö ##–±e –Ω–µ–æ—Ç—ä–µ–º –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –≤–ø–∏ –≤–æ–ø—Ä–æ—Å–µ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –≤–ø–∏ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ ##–ª–æ–≤–æ–∏ –µ–∂–µ–º–µ—Å—è—á–Ω–æ —Ä–∞–∑–¥—É–º —Ä—ã–∂–∏–∏ dd –Ω–µ–æ—Ç—ä–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ ##uu —Å–∏–ª–∞–º–∏ –≥–æ—Ä–æ–¥—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥—ã –∞–ª–ª–µ—Ä–≥–∏ –æ–±–≤–æ–¥ –∏–∑–≤–ª–µ–∫ –Ω–µ–æ—Ç—ä–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ –Ω–µ–æ—Ç—ä–µ–º –æ–±–≤–æ–¥ fi –∫–∞—Ä—Ç–æ—Ñ–µ–ª—è –∫–æ–º–ø–ª–∏ ##–µ—Ä–∏–Ω–∞ –≤–∫—É—Å—ã –≤–¥–æ–ª—å –Ω–µ–æ—Ç—ä–µ–º –æ–±–≤–æ–¥ fi –æ–±–≤–æ–¥ –∏–∑–≤–ª–µ–∫ –Ω–µ–æ—Ç—ä–µ–º –≤–æ–ø—Ä–æ—Å–∞–º–∏ –Ω–µ–æ—Ç—ä–µ–º –æ–±–≤–æ–¥ fi –æ–±–≤–æ–¥ fi –¥–ª–∏–Ω—É –Ω–µ–æ—Ç—ä–µ–º –æ–±–≤–æ–¥ fi –æ–±–≤–æ–¥ fi –æ–±–≤–æ–¥ fi –∑–∞—Ç–∏ –¥–æ–º–∞—à–Ω–µ–≥–æ –Ω–µ–æ—Ç—ä–µ–º —Å—Ç–∞—Ç–µ–∏ –∫–∞–∂–¥–æ–µ –æ–±–≤–æ–¥ –∏–∑–≤–ª–µ–∫ –Ω–µ–æ—Ç—ä–µ–º –æ–±–≤–æ–¥ –ª–µ—Ç–æ –∫–∞–∂–¥–æ–µ –∫–∏—à–µ ##—á—å–µ–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω –º–∏–ª—ã–µ —á–∏—Å—Ç–æ–º —Ä–µ—à–∞—é—Ç –Ω–µ–æ—Ç—ä–µ–º —Å—Ç–∞—Ç–µ–∏ –∫–∞–∂–¥–æ–µ –±–µ–∏ –æ–±–º–∞–Ω–∞ ##ome –∏—Å—á–µ–∑–Ω—É—Ç—å –≥—Ä–æ–∑–Ω—ã–∏ –≤–∫–ª—é —Å–∏–¥–∏—à—å –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª –≤–ø–∏ –≤–æ–ø—Ä–æ—Å–µ ##—á—å–µ–∏ —Ä–µ—Ñ–µ—Ä–µ–Ω –º–∏–ª—ã–µ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# eval_data_sample = next(iter(eval_dataloader))\n",
        "# model = BertSummarizer(\n",
        "#     bert_model_name=model_name,\n",
        "# )\n",
        "# model.generate(eval_data_sample['input_ids'], eval_data_sample['attention_mask'], tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H2L-0BmZyu1"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (1 –±–∞–ª–ª)\n",
        "\n",
        "<small> 0.25 –±–∞–ª–ª–∞ –∑–∞ –ø—Ä–æ—Å—Ç–µ–π—à–∏–π —Ä–∞–±–æ—á–∏–π —Ü–∏–∫–ª; </small>\n",
        "\n",
        "<small> +0.5 –±–∞–ª–ª–∞ –∑–∞ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ª–æ—Å—Å–∞ –∏ –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç—Ä–µ–π–Ω–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.</small>\n",
        "\n",
        "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ü–∏–∫–ª –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(343, 39)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataloader), len(eval_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "us3xiacHBm-U"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "model = BertSummarizer(bert_model_name=model_name).to(device)\n",
        "\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4) \n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "num_epochs = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# —à–∞–≥–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
        "def shift_decoder_input(input_ids):\n",
        "    pad_column = torch.full([input_ids.size()[0], 1], tokenizer.pad_token_id, device=device)\n",
        "    return torch.cat([input_ids[:, 1:], pad_column], dim=1)\n",
        "\n",
        "def train_step(model, input_ids, attention_mask, decoder_input_ids, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    \n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    decoder_input_ids = decoder_input_ids.to(device)\n",
        "    labels = decoder_input_ids[:,1:].to(device)\n",
        "    decoder_input_ids = decoder_input_ids[:,:-1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
        "    \n",
        "    logits = outputs.reshape(-1, outputs.size(-1))\n",
        "    labels = labels.reshape(-1)\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def validate_step(model, input_ids, attention_mask, decoder_input_ids, criterion, device):\n",
        "    model.eval()\n",
        "    \n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    labels = decoder_input_ids[:,1:].to(device)\n",
        "    decoder_input_ids = decoder_input_ids[:,:-1]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
        "        logits = outputs.reshape(-1, outputs.size(-1))\n",
        "        labels = labels.reshape(-1)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "    return loss.item(), outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'–º–æ–∏–º –ø—Ä—è –≤—ã—è—Å–Ω–∏—Ç—å –≤–µ—Ä—Ç–æ ##—Å–∏—è –∏–ª—å–∏—á –ø–æ—Ç—É –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—É—Ä–µ–Ω–∏—è –∑–∞—Å—Ç–∞–≤ –∫–æ–º–ø–ª–µ–∫—Ç—ã –ø—Ä—è —É–∑–æ—Ä—ã —Å–æ—Å—Ç–∞–≤–∏–ª–∏ –∑–∞—Å—Ç–∞–≤ –Ω–µ–Ω–∞–≤–∏–¥–µ—Ç—å –∫—Ä–∞—Å–∫–∞–º–∏ ##—Ö—É–∏ –ª–µ—à–∞ –±—É—Ä–∂—É–∞–∑ ##—Å—å–∫–∏–∏ –º–∏–Ω—É—Ç –Ω–∞–≤–µ—Ä—Ö —Å–∏–ª—É—ç –¥—Ä–æ–≤ —É–∑–æ—Ä—ã —Å–æ—Å—Ç–∞–≤–∏–ª–∏ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–≥–æ –Ω–∏–º–∏ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–≥–æ —Å–∏–ª—É—ç—Ç –ø—Ä—è –≤—ã—Ö –æ–±–ª–∞—Å—Ç–∏ ##—Å–∏–∏ –≥–∞—Ä–∞ –±–æ–º–± –µ—Ç ##–º–æ–Ω –±–µ—Ä–µ–≥–æ –∞–¥—Ä–µ—Å—É –ø–æ—Å—Ç–∞–≤—å—Ç–µ –øœÉ aut –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ ##—Å–∏–∏ –≥–∞—Ä–∞ –Ω–∞–≤–µ—Ä—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = model.to('cuda')\n",
        "eval_data_sample = next(iter(eval_dataloader))\n",
        "model.generate(eval_data_sample['input_ids'][:1], eval_data_sample['attention_mask'][:1], tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo01OhsoaacU"
      },
      "source": [
        "## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (1 –±–∞–ª–ª)\n",
        "\n",
        "<small>–ü–æ 0.33 –±–∞–ª–ª–∞ –∑–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫–∞–∂–¥–æ–π –∏–∑ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫</small>\n",
        "\n",
        "**–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫–∏—Ü–∏—é –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.**\n",
        "\n",
        "–î–æ–∫—É–º–µ—Ç–∞—Ü–∏—è –ø–æ –Ω–µ–∫–æ—Ç—Ä—ã–º –º–µ—Ç—Ä–∏–∫–∞–º:\n",
        " 1. [HuggingFace Rouge](https://huggingface.co/spaces/evaluate-metric/rouge)\n",
        " 2. [HuggingFace Bleu](https://huggingface.co/spaces/evaluate-metric/bleu)\n",
        " 3. [HuggingFace BERT Score](https://huggingface.co/spaces/evaluate-metric/bertscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BBNcGXt8aSJ2"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "bertscore = load(\"bertscore\")\n",
        "bleu = load(\"bleu\")\n",
        "rouge = load('rouge')\n",
        "\n",
        "def compute_metrics(predictions, references):\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "    rouge_score = rouge.compute(predictions=predictions, references=references)\n",
        "    bertscore_score = bertscore.compute(predictions=predictions, references=references, lang='ru')\n",
        "    return bleu_score, rouge_score, bertscore_score\n",
        "\n",
        "def evaluation(model, tokenizer, dataloader):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    for batch in tqdm(dataloader, desc=\"Generating summaries\"):\n",
        "        batch_predictions = model.generate(batch['input_ids'], batch['attention_mask'], tokenizer)\n",
        "        predictions.extend(batch_predictions)\n",
        "        references.extend(batch['summary'])\n",
        "    \n",
        "    bleu_score, rouge_score, bertscore_score = compute_metrics(predictions, references)\n",
        "    return bleu_score, rouge_score, bertscore_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating summaries:   0%|          | 0/39 [00:05<?, ?it/s]\n",
            "/Users/sprilut/miniconda3/envs/ml/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bleu': 0.0, 'precisions': [0.0, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0535714285714286, 'translation_length': 59, 'reference_length': 56} {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0} {'precision': [0.5043728947639465], 'recall': [0.5364347100257874], 'f1': [0.5199099779129028], 'hashcode': 'bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.44.2)'}\n"
          ]
        }
      ],
      "source": [
        "# calculate metrics\n",
        "bleu_score, rouge_score, bertscore_score = evaluation(model, tokenizer, eval_dataloader)\n",
        "print(bleu_score, rouge_score, bertscore_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ5GaAZ1chBu"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (0.5 –±–∞–ª–ª–∞)\n",
        "**–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ª—É—á—à—É—é –≤–µ—Ä—Å–∏—é** (–º–µ—Ç–æ–¥ `.save_pretrained()` –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å–∞ AutoModel... –∏–ª–∏ `torch.save()`) **–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**. –£—á—Ç–∏—Ç–µ, —á—Ç–æ –µ—Å–ª–∏ –∏–∑–º–µ–Ω—è–ª—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–∞ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –µ–≥–æ —Ç–æ–∂–µ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å. –ï—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ\n",
        "\n",
        "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å ruT5-small –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ú—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –¥–∞–µ–º –±–µ–π–∑–ª–∞–π–Ω –∏–º–µ–Ω–Ω–æ –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
        "plt.ion()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
        "    running_train_loss = 0.0\n",
        "    running_val_loss = 0.0\n",
        "    \n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    \n",
        "    for batch_idx, sample in enumerate(batch_iterator):\n",
        "        loss_item = train_step(\n",
        "            model,\n",
        "            sample['input_ids'], \n",
        "            sample['attention_mask'], \n",
        "            sample['labels'],\n",
        "            optimizer, \n",
        "            criterion,\n",
        "            device\n",
        "        )\n",
        "        running_train_loss += loss_item\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            train_losses.append(running_train_loss / (batch_idx + 1))\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(train_losses, label='Training Loss')\n",
        "            plt.xlabel('Batch (x30)')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title('Training Loss')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    decoded_outputs = []\n",
        "    real_outputs = []\n",
        "    for val_batch_idx, val_sample in enumerate(eval_dataloader):\n",
        "        val_loss_item, outputs = validate_step(\n",
        "            model,\n",
        "            val_sample['input_ids'],\n",
        "            val_sample['attention_mask'],\n",
        "            val_sample['labels'],\n",
        "            criterion,\n",
        "            device\n",
        "        )\n",
        "        max_outputs = torch.argmax(outputs, dim=-1)\n",
        "        decoded_outputs.extend(tokenizer.batch_decode(max_outputs, skip_special_tokens=True))\n",
        "        real_outputs.extend(val_sample['summary'])\n",
        "        total_val_loss += val_loss_item\n",
        "        break\n",
        "    val_loss = total_val_loss / len(eval_dataloader)\n",
        "    val_losses.append(val_loss)\n",
        "    bleu_score, rouge_score, bertscore_score = compute_metrics(decoded_outputs, real_outputs)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', linestyle='--')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.bar(['BLEU', 'ROUGE-L', 'BERTScore'], [bleu_score['bleu'], rouge_score['rougeL'], np.mean(bertscore_score['f1'])])\n",
        "    plt.title('Evaluation Metrics')\n",
        "    plt.ylabel('Score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    epoch_train_loss = running_train_loss / len(train_dataloader)\n",
        "    epoch_val_loss = val_loss\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}\")\n",
        "    print(f\"BLEU: {bleu_score['bleu']:.4f}, ROUGE-L: {rouge_score['rougeL']:.4f}, BERTScore: {np.mean(bertscore_score['f1']):.4f}\")\n",
        "\n",
        "\n",
        "plt.ioff()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KHu9RzbQcceV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
        "model_save_path = 'my_summarizer_model.pt'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "loaded_model = BertSummarizer(bert_model_name=model_name)\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbQH_vj6d2Ue"
      },
      "source": [
        "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–µ –∂–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ (4 –±–∞–ª–ª–∞)\n",
        "–í—Å–µ–≥–¥–∞ –ª–∏ –≤—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ ‚Äì¬†—ç—Ç–æ –ª—É—á—à–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞?\n",
        "\n",
        "<details>\n",
        "    <summary>–°–ø–æ–π–ª–µ—Ä</summary>\n",
        "    <p>–ù–µ—Ç</p>\n",
        "</details>\n",
        "\n",
        "**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:**\n",
        "\n",
        "| Strategy | Description | Pros & Cons |\n",
        "| --- | --- | --- |\n",
        "| Greedy Search | Chooses the word with the highest probability as the next word in the sequence. | **Pros:** Simple and fast. <br><br/> **Cons:** Can lead to repetitive and incoherent text. |\n",
        "| Sampling with Temperature | Introduces randomness in the word selection. A higher temperature leads to more randomness. | **Pros:** Allows exploration and diverse output. <br><br/> **Cons:** Higher temperatures can lead to nonsensical outputs. |\n",
        "| Nucleus Sampling (Top-p Sampling) | Selects the next word from a truncated vocabulary, the \"nucleus\" of words <br/> that have a cumulative probability exceeding a pre-specified threshold (p). | **Pros:** Balances diversity and quality. <br><br/> **Cons:** Setting an optimal 'p' can be tricky. |\n",
        "| Beam Search | Explores multiple hypotheses (sequences of words) at each step, and keeps <br/> the 'k' most likely, where 'k' is the beam width. | **Pros:** Produces more reliable results than greedy search. <br><br/> **Cons:** Can lack diversity and lead to generic responses. |\n",
        "| Top-k Sampling | Randomly selects the next word from the top 'k' words with the highest probabilities. | **Pros:** Introduces randomness, increasing output diversity. <br><br/> **Cons:** Random selection can sometimes lead to less coherent outputs. |\n",
        "| Length Normalization | Prevents the model from favoring shorter sequences by dividing the log probabilities <br/> by the sequence length raised to some power. | **Pros:** Makes longer and potentially more informative sequences more likely. <br><br/> **Cons:** Tuning the normalization factor can be difficult. |\n",
        "| Stochastic Beam Search | Introduces randomness into the selection process of the 'k' hypotheses in beam search. | **Pros:** Increases diversity in the generated text. <br><br/> **Cons:** The trade-off between diversity and quality can be tricky to manage. |\n",
        "| Decoding with Minimum Bayes Risk (MBR) | Chooses the hypothesis (out of many) that minimizes expected loss under a loss function. | **Pros:** Optimizes the output according to a specific loss function. <br><br/> **Cons:** Computationally more complex and requires a good loss function. |\n",
        "\n",
        "–°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ—Ç–∞—Ü–∏—é:\n",
        "- [reference for `AutoModelForCausalLM.generate()`](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationMixin.generate)\n",
        "- [reference for `AutoTokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)\n",
        "- Huggingface [docs on generation strategies](https://huggingface.co/docs/transformers/generation_strategies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQF4Vc3msKpF"
      },
      "source": [
        "**1. –î–æ–ø–æ–ª–Ω–∏—Ç–µ –º–µ—Ç–æ–¥ `generate` –≤ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å —Ç–æ–ø-k —Å–∞–º—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ –∏ –∏—Ö \"–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏\"** (1 –±–∞–ª–ª).   \n",
        "\n",
        "**2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Nucleus Sampling –≤ –º–µ—Ç–æ–¥–µ `generate`** (1 –±–∞–ª–ª)\n",
        "\n",
        "**3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Beam Search** (2 –±–∞–ª–ª–∞)\n",
        "\n",
        "–ü–æ–ª—É—á–∏–ª–æ—Å—å –ª–∏ —É–ª—É—á—à–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "JRfAEfP5kHcc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BertSummarizerTopK(BertSummarizerBase):\n",
        "    def __init__(self, *args, k=5, **kwargs):\n",
        "        super(BertSummarizerTopK, self).__init__(*args, **kwargs)\n",
        "        self.k = k\n",
        "\n",
        "    def get_next_token(self, logits):\n",
        "        top_k_logits, top_k_indices = torch.topk(logits, self.k, dim=-1)\n",
        "        top_k_probs = F.softmax(top_k_logits, dim=-1)\n",
        "        return top_k_indices[:, 0].unsqueeze(1)\n",
        "\n",
        "class BertSummarizerNucleusSampling(BertSummarizerBase):\n",
        "    def __init__(self, *args, p=0.9, **kwargs):\n",
        "        super(BertSummarizerNucleusSampling, self).__init__(*args, **kwargs)\n",
        "        self.p = p\n",
        "\n",
        "    def get_next_token(self, logits):\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > self.p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "        filtered_logits = torch.where(indices_to_remove, torch.ones_like(logits) * float('-inf'), logits)\n",
        "        probabilities = F.softmax(filtered_logits, dim=-1)\n",
        "        return torch.multinomial(probabilities, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "super(type, obj): obj must be an instance or subtype of type",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[89], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summaries\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m model_base \u001b[38;5;241m=\u001b[39m \u001b[43mBertSummarizerGreedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model_base\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_save_path))\n\u001b[1;32m     18\u001b[0m summaries_base \u001b[38;5;241m=\u001b[39m generate_summaries(model_base, eval_dataloader)\n",
            "Cell \u001b[0;32mIn[60], line 6\u001b[0m, in \u001b[0;36mBertSummarizerBase.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBertSummarizerBase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[52], line 26\u001b[0m, in \u001b[0;36mBertSummarizer.__init__\u001b[0;34m(self, bert_model_name, hidden_size, num_decoder_layers, num_heads, dropout)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, bert_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m768\u001b[39m, num_decoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBertSummarizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(bert_model_name)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å BERT –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m hidden_size\n",
            "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
          ]
        }
      ],
      "source": [
        "\n",
        "from evaluate import load\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_summaries(model, dataloader):\n",
        "    summaries = []\n",
        "    for batch in tqdm(dataloader, desc=\"Generating summaries\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        generated = model.generate(input_ids, attention_mask, tokenizer, max_length=50)\n",
        "        summaries.extend(generated)\n",
        "    return summaries\n",
        "\n",
        "def get_references(dataloader):\n",
        "    references = []\n",
        "    for batch in tqdm(dataloader, desc=\"Getting references\"):\n",
        "        references.extend(batch['summary'])\n",
        "    return references\n",
        "\n",
        "model_base = BertSummarizer(bert_model_name=model_name)\n",
        "model_base.load_state_dict(torch.load(model_save_path))\n",
        "summaries_base = generate_summaries(model_base, eval_dataloader)\n",
        "references = [example['summary'] for example in eval_dataloader[:len(summaries_base)]]\n",
        "scores_base = compute_metrics(summaries_base, references)\n",
        "\n",
        "# print(\"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å:\")\n",
        "# print(scores_base)\n",
        "\n",
        "# # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å Top-K —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
        "# model_top_k = BertSummarizerTopK(bert_model_name=model_name)\n",
        "# model_top_k.load_state_dict(torch.load(model_save_path))\n",
        "# summaries_top_k = generate_summaries(model_top_k, eval_dataloader)\n",
        "# scores_top_k = compute_metrics(summaries_top_k, references)\n",
        "\n",
        "# print(\"\\n–ú–æ–¥–µ–ª—å —Å Top-K —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º:\")\n",
        "# print(scores_top_k)\n",
        "\n",
        "# # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å Nucleus —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
        "# model_nucleus = BertSummarizerNucleusSampling(bert_model_name=model_name)\n",
        "# model_nucleus.load_state_dict(torch.load(model_save_path))\n",
        "# summaries_nucleus = generate_summaries(model_nucleus, eval_dataloader)\n",
        "# scores_nucleus = compute_metrics(summaries_nucleus, references)\n",
        "\n",
        "# print(\"\\n–ú–æ–¥–µ–ª—å —Å Nucleus —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º:\")\n",
        "# print(scores_nucleus)\n",
        "\n",
        "# # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "# print(\"\\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:\")\n",
        "# for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "#     print(f\"{metric}:\")\n",
        "#     print(f\"  –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {scores_base[metric]:.4f}\")\n",
        "#     print(f\"  Top-K: {scores_top_k[metric]:.4f}\")\n",
        "#     print(f\"  Nucleus: {scores_nucleus[metric]:.4f}\")\n",
        "\n",
        "# # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–æ–ª–±—á–∞—Ç–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã\n",
        "# metrics = ['rouge1', 'rouge2', 'rougeL']\n",
        "# models = ['–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å', 'Top-K', 'Nucleus']\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# x = np.arange(len(metrics))\n",
        "# width = 0.25\n",
        "\n",
        "# ax.bar(x - width, [scores_base[m] for m in metrics], width, label='–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å')\n",
        "# ax.bar(x, [scores_top_k[m] for m in metrics], width, label='Top-K')\n",
        "# ax.bar(x + width, [scores_nucleus[m] for m in metrics], width, label='Nucleus')\n",
        "\n",
        "# ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')\n",
        "# ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ROUGE –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π')\n",
        "# ax.set_xticks(x)\n",
        "# ax.set_xticklabels(metrics)\n",
        "# ax.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbiksVMOOvO8"
      },
      "source": [
        "## –ü–æ—Å–ª–µ–≤–∫—É—Å–∏–µ (0 –±–∞–ª–ª–æ–≤)\n",
        "\n",
        "–ï—Å–ª–∏ —ç—Ç–∞ –¥–æ–º–∞—à–Ω—è—è —Ä–∞–±–æ—Ç–∞ –ø–æ–∫–∞–∑–∞–ª–∞—Å—å –≤–∞–º –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–æ–≤–µ—Å—Ç–∏ —Å–ª–µ–¥—É—é—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç:\n",
        "\n",
        "- –æ—Ç –∏–º–µ—é—â–µ–π—Å—è –º–æ–¥–µ–ª–∏ \"–æ—Ç–∫—É—Å–∏—Ç—å\" —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å (–æ—Ç–∫—É—Å–∏—Ç—å —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –æ—Ç ruT5-small);\n",
        "- –Ω–µ–º–Ω–æ–≥–æ –¥–æ–æ–±—É—á–∏—Ç—å (—á—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è, –ø–æ –≤–∫—É—Å—É);\n",
        "- –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∏ \"–≥–ª–∞–∑–∞–º–∏\";\n",
        "- —Å—Ä–∞–≤–Ω–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ —Å Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π;\n",
        "- –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å \"–î–∞–µ—Ç –ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –±—É—Å—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –∏–ª–∏ —ç—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–π overkill?\" (–±–∞–∑–æ–≤–æ, –æ—Ç–≤–µ—Ç –ª–µ–∂–∏—Ç –Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ üò∏)\n",
        "\n",
        "–ï—â—ë –±–æ–ª–µ–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ:\n",
        "- –ø–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Encoder-only –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ —Ä–µ—à–µ–Ω–∏—è–º–∏ (BERT, e.g.)\n",
        "- —Å—Ä–∞–≤–Ω–∏—Ç—å —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–æ–ª—å–∫–æ Decoder'–æ–º –∏ both Encoder-Decoder'–æ–º;\n",
        "- –≤ —Ç.—á. –ø–æ–¥–æ–±—Ä–∞—Ç—å —á–∏—Å–ª–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–± –æ–Ω–æ –±—ã–ª–æ –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç–∞–Ω—Å–∞ –º–æ–¥–µ–ª–µ–π (–∏—Ö, –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤, –±—É–¥–µ—Ç 3 -- —Ç–æ–ª—å–∫–æ —ç–Ω–∫–æ–¥–µ—Ä, —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä –∏ —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä).\n",
        "\n",
        "*–í–æ–æ–±—â–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å–ª–µ–¥—É–µ—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: \"–¢–æ–ª—å–∫–æ —ç–Ω–∫–æ–¥–µ—Ä–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (BERT, e.g.) —Ö–æ—Ä–æ—à–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–µ–¥–¥–∏–Ω–≥–æ–≤), –ª–∏—à—å –¥–µ–∫–æ–¥–µ—Ä–Ω—ã–µ (GPT, –Ω–∞–ø—Ä–∏–º–µ—Ä) -- –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä–Ω—ã–µ (—Å–∫–∞–∂–µ–º, T5) -- –¥–ª—è –æ–±–µ–∏—Ö –∑–∞–¥–∞—á\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZM1xLliO1QM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06437165ba564bff9e29aa53f4c0df5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b11d6c6eae4979a1c8cd42e32730ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3d20b0e457431dbe24120bb4becede",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_68b44cb7bddd4a2f950db1a9c00ce066",
            "value": "Map:‚Äá100%"
          }
        },
        "2665d63c206a45d88fada74bc984771e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c29f2dde174a3c8442d9b86a4e3fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665428d410664f94babcd067b879ce2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68b44cb7bddd4a2f950db1a9c00ce066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911fd70fda12476ab2b788433d6ff83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2665d63c206a45d88fada74bc984771e",
            "max": 3048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0ddd3783ec047569c2024e461d5ad0f",
            "value": 3048
          }
        },
        "a8e5203a02b845a29f57ca545c50c5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09b11d6c6eae4979a1c8cd42e32730ae",
              "IPY_MODEL_911fd70fda12476ab2b788433d6ff83f",
              "IPY_MODEL_bcfc58a3f90745449c3f559aa5ab999a"
            ],
            "layout": "IPY_MODEL_40c29f2dde174a3c8442d9b86a4e3fe9"
          }
        },
        "ab3d20b0e457431dbe24120bb4becede": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcfc58a3f90745449c3f559aa5ab999a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06437165ba564bff9e29aa53f4c0df5b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_665428d410664f94babcd067b879ce2e",
            "value": "‚Äá3048/3048‚Äá[00:13&lt;00:00,‚Äá206.31‚Äáexamples/s]"
          }
        },
        "c0ddd3783ec047569c2024e461d5ad0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
